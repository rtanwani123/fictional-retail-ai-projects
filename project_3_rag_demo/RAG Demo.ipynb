{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNxBu0xXo1nuej9wWe7ASOp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":null,"metadata":{"id":"usdu8MXBk_sP","executionInfo":{"status":"error","timestamp":1761160623597,"user_tz":-60,"elapsed":91431,"user":{"displayName":"Raj","userId":"18248747456266615375"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"5ed16268-5ae3-4ea6-e07d-fe238df8cbe2"},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m31.4/31.4 MB\u001b[0m \u001b[31m19.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m232.6/232.6 kB\u001b[0m \u001b[31m5.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25h"]},{"output_type":"error","ename":"FileNotFoundError","evalue":"[Errno 2] No such file or directory: '/content/fictional_retail_docs'","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/tmp/ipython-input-522762242.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0mfile_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 131\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mfilename\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    132\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlower\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mendswith\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".pdf\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    133\u001b[0m         \u001b[0mpdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPdfReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfolder_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilename\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/content/fictional_retail_docs'"]}],"source":["# ============================================================\n","# PROJECT OVERVIEW — Fictional Retail Co. RAG Demo\n","# ============================================================\n","# This project builds a simple Retrieval-Augmented Generation (RAG) system\n","# using only free and open-source tools.\n","#\n","# RAG means we first \"retrieve\" the most relevant text from documents,\n","# and then \"generate\" an answer using a language model.\n","#\n","# Example:\n","# Fictional Retail Co. has internal documents.\n","# We want to ask questions like:\n","#   - What is the return policy?\n","#   - How can customers reach support?\n","# and get accurate answers from those documents.\n","#\n","# ============================================================\n","# SIMPLE EXPLANATION OF EACH STEP\n","# ============================================================\n","#\n","# Step 1 — Install the Tools\n","# We start by installing all the computer “tools” (Python libraries) we’ll need.\n","# These include:\n","# - Transformers and Sentence-Transformers → for understanding and generating text.\n","# - FAISS → a super-fast search engine for finding similar text.\n","# - PyPDF2 → to read PDF files.\n","# - Gradio → to build a simple chatbot interface.\n","#\n","# Think of this step as putting all your ingredients on the kitchen counter before cooking.\n","#\n","# Step 2 — Import the Tools\n","# Now that everything is installed, we tell Python we want to use them in our code using \"import\".\n","# We also set up where our data (PDFs) is stored — in a folder called /content/fictional_retail_docs.\n","#\n","# Step 3 — Read & Split the Documents\n","# We open each PDF and extract the text.\n","# Then we split the big text into smaller chunks (like cutting a large paragraph into smaller paragraphs).\n","#\n","# Why? Because the model can’t read super long text at once — it’s like giving it a few sentences at a time to focus better.\n","# We use:\n","#   - chunk_size = 1000 characters (each piece)\n","#   - overlap = 200 (to give some overlap so it remembers context)\n","#\n","# Step 4 — Turn Text into Numbers (Embeddings) & Build a Search Index\n","# Computers don’t understand words directly — they understand numbers.\n","# So, we use a model called all-MiniLM-L12-v2 to convert each text chunk into a set of numbers (called embeddings).\n","# Then we store all these embeddings in FAISS, a kind of searchable “brain” that can quickly find which text chunks\n","# are most similar to a question.\n","#\n","# Step 5 — Load the Answer Generator (FLAN-T5)\n","# Now we load a text generation model — flan-t5-base — from Google.\n","# This model can read a question and some context, and then write a short, clear answer.\n","#\n","# Step 6 — Ask Questions Safely (RAG Query Function)\n","# Here we connect everything together.\n","# When we ask a question:\n","#   1. The system searches FAISS to find the most relevant chunks (top-k).\n","#   2. It limits how much text is passed to the model (to avoid errors).\n","#   3. It gives this text to FLAN-T5 and asks it to generate an answer.\n","#\n","# Step 7 — Test the System\n","# We test it with a few sample questions — one from each file.\n","# This helps confirm that the model is reading the right chunks and giving sensible answers.\n","# It also prints which PDF file the answer came from, so you know the source.\n","#\n","# Step 8 — Make It Interactive with Gradio\n","# Finally, we build a simple chat interface where anyone can type a question and get an answer.\n","# This makes your project more user-friendly — like a mini AI chatbot for Fictional Retail Co.\n","#\n","# ============================================================\n","# SYSTEM FLOW\n","# ============================================================\n","# 1. Load and split documents\n","# 2. Turn text into embeddings\n","# 3. Store embeddings in FAISS\n","# 4. When user asks a question:\n","#       → Find most similar text pieces\n","#       → Give them to the model\n","#       → Generate and return the answer\n","# 5. Optional: Ask more questions via the Gradio interface\n","#\n","# ============================================================\n","# TOOLS USED (All Free)\n","# ============================================================\n","# - SentenceTransformer: all-MiniLM-L12-v2 (for embeddings)\n","# - Hugging Face Model: google/flan-t5-base (for generating answers)\n","# - FAISS: for searching similar text\n","# - PyPDF2: for reading PDFs\n","# - Gradio: for the chatbot interface\n","#\n","# Everything in this project is open-source and 100% free.\n","# No paid API keys or cloud accounts are needed.\n","# ============================================================\n","\n","\n","# =========================\n","# Step 1: Install Libraries\n","# =========================\n","!pip install --quiet sentence-transformers transformers faiss-cpu PyPDF2 gradio\n","\n","# =========================\n","# Step 2: Import Libraries\n","# =========================\n","import os\n","import faiss\n","import numpy as np\n","from PyPDF2 import PdfReader\n","from sentence_transformers import SentenceTransformer\n","from transformers import AutoTokenizer, AutoModelForSeq2SeqLM, pipeline\n","import gradio as gr\n","\n","# Folder containing your documents\n","folder_path = \"/content/fictional_retail_docs\"\n","\n","# =========================\n","# Step 3: Read and Split PDFs\n","# =========================\n","def chunk_text(text, chunk_size=1000, overlap=200):\n","    \"\"\"Split long text into smaller overlapping chunks for better processing.\"\"\"\n","    chunks = []\n","    start = 0\n","    while start < len(text):\n","        end = min(start + chunk_size, len(text))\n","        chunks.append(text[start:end])\n","        start += chunk_size - overlap\n","    return chunks\n","\n","all_chunks = []\n","file_names = []\n","\n","for filename in os.listdir(folder_path):\n","    if filename.lower().endswith(\".pdf\"):\n","        pdf = PdfReader(os.path.join(folder_path, filename))\n","        text = \"\"\n","        for page in pdf.pages:\n","            page_text = page.extract_text() or \"\"\n","            text += page_text.strip() + \" \"\n","        chunks = chunk_text(text)\n","        all_chunks.extend(chunks)\n","        file_names.extend([filename] * len(chunks))\n","\n","print(f\"Loaded {len(all_chunks)} text chunks from {len(os.listdir(folder_path))} PDFs.\")\n","\n","# =========================\n","# Step 4: Create Embeddings and Build FAISS Index\n","# =========================\n","embed_model = SentenceTransformer(\"all-MiniLM-L12-v2\")\n","embeddings = embed_model.encode(all_chunks, convert_to_numpy=True, show_progress_bar=True)\n","\n","dimension = embeddings.shape[1]\n","index = faiss.IndexFlatL2(dimension)\n","index.add(embeddings)\n","\n","print(\"FAISS index created and populated with document chunks.\")\n","\n","# =========================\n","# Step 5: Load the Answer Generation Model\n","# =========================\n","tokenizer = AutoTokenizer.from_pretrained(\"google/flan-t5-base\")\n","model = AutoModelForSeq2SeqLM.from_pretrained(\"google/flan-t5-base\")\n","gen_pipeline = pipeline(\"text2text-generation\", model=model, tokenizer=tokenizer)\n","\n","# =========================\n","# Step 6: Define the RAG Query Function\n","# =========================\n","def rag_query(query, k=2, max_new_tokens=200):\n","    \"\"\"Retrieve top-k relevant chunks and generate an answer.\"\"\"\n","    query_emb = embed_model.encode([query], convert_to_numpy=True)\n","    distances, indices = index.search(query_emb, k)\n","    retrieved_chunks = [all_chunks[i] for i in indices[0]]\n","    sources = [file_names[i] for i in indices[0]]\n","\n","    # Limit total context size to avoid long input issues\n","    context = \" \".join(retrieved_chunks)\n","    if len(context) > 3500:\n","        context = context[:3500]\n","\n","    # Build the prompt for FLAN-T5\n","    prompt = f\"Answer the question based only on the context below:\\n\\nContext:\\n{context}\\n\\nQuestion: {query}\"\n","    response = gen_pipeline(prompt, max_new_tokens=max_new_tokens, do_sample=False)[0]['generated_text']\n","\n","    return {\"answer\": response, \"sources\": sources}\n","\n","# =========================\n","# Step 7: Test the System\n","# =========================\n","sample_questions = {\n","    \"Returns\": \"What is the return policy?\",\n","    \"Warranty\": \"How long is the warranty period?\",\n","    \"Customer Support\": \"How can customers contact support?\",\n","    \"Loyalty\": \"How does the loyalty program work?\"\n","}\n","\n","print(\"\\nTesting RAG system...\\n\")\n","for topic, question in sample_questions.items():\n","    result = rag_query(question)\n","    print(f\"Question ({topic}): {question}\")\n","    print(f\"Answer: {result['answer']}\")\n","    print(f\"Source Documents: {result['sources']}\")\n","    print(\"-\" * 80)\n","\n","# =========================\n","# Step 8: Gradio Interface\n","# =========================\n","def ask_rag(query):\n","    result = rag_query(query)\n","    answer = result[\"answer\"]\n","    source = \", \".join(set(result[\"sources\"]))\n","    return f\"Answer: {answer}\\n\\nSource Documents: {source}\"\n","\n","demo = gr.Interface(fn=ask_rag, inputs=\"text\", outputs=\"text\", title=\"Fictional Retail Co. RAG Assistant\")\n","demo.launch(share=False)\n"]}]}